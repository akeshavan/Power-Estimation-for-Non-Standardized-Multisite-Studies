A limitation of our model is the assumption of independence between the unobserved effect ($D_{U,j}$) at a particular site , $j$, with the scaling factor of that site ($a_j$). This assumption does not hold if patients with more severe disease have tissues with different properties, that when scanned, show different regional contrast than healthy controls. As shown in the Appendix, the calculation of the unconditional variance of the observed estimate (equation \ref{var_unobserved}) can get quite complicated. However, we addressed this issue for multiple sclerosis patients, by showing that the scaling factors from healthy control are very similar to those derrived from an MS population. The largest difference in scaling factors between HC versus MS patients was for white matter volume, where $a_{MS} = .967$ and $a_{HC} = .975$. A two-sample T test between the scaling factors resulted in a p-value of $0.88$, showing that we could not detect a significant difference between scaling factors between HC and MS. This part of the study was limited in that we only scanned patients at two scanners, while the healthy controls were scanned at 20, so we could not estimate a patient-derived $CV_a$, which is the direct input to the power equation. However, the similarity between scaling factors for the subcortical gray matter, cortical gray matter and white matter volumes between the MS and HC populations suggests that, given careful editing of volumes on the disease population, the independence assumption holds for MS. For researchers studying other disease, it may be useful to scan healthy controls and patients before and after an upgrade or sequence change to test the validity of the independence assumption.

Even though we did not standardize the protocols and scanners within this study, the consortium is unbalanced in that there are 16 3T scanners of which 11 are Siemens. Of the Siemens 3T scanners, there is little variability in TR, TE and TI, however, there is more variance in the use of parallel imaging, the number of channels in the head coil (12, 20 or 32), the read-out direction (FH, HF, RL or AP), and the field of view. We could not detect differences in scan-rescan reliability between field strengths, similar to the findings of \cite{Jovicich_2009}. Wolz and colleagues also could not detect differences in scan-rescan reliabilities of the hippocampus volumes estimated by the LEAP algorithm, but they detected a small bias between field strengths, where the hippocampus volumes in the 3T ADNI scanners were 1.17 \% larger than the 1.5T \cite{Wolz_2014}. A two-sample T-test with unequal variances was run between the scaling factors of the 1.5T versus 3T scanners, and we could not detect differences in any ROI except for the left- and right- amydgala. We found that the scaling factors were lower than the 3T scanners (.9 versus 1.02), meaning that the amygdala volume estimates from the 1.5T were larger than those of the 3T. However, this interpretation is limited due to the small sample size of 1.5T scanners in this consortium.  