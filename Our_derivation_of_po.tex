Our derivation of power for a multisite study which was based on scaled, systematic error from MRI defines hard thresholds for the amount of acceptable scaling factor variability, $CV_{a}$. Many conditions contribute to the $CV_{a}$ cut-off, such as the total number of subjects, sites, effect size, and false positive rate. In Figure \ref{fig:cv_j}, we show the distribution of experimental $CV_{a}$ values across all Freesurfer aseg ROIs to compare with power curves of various sample sizes. The maximum $CV_{a}$ value is 9\%, and with enough subjects and sites, this falls well below the maximum acceptable $CV_{a}$ value. However, with the minimum number of subjects and sites, the power curves of figure \ref{fig:cv_j} show that the maximum acceptable $CV_{\alpha}$ must be below 5\% for 80\% power. If we minimize the total number of subjects to 2260 for the 20 sites in our study, the $CV_{a}$ of the amygdala does not meet this requirement (see table \ref{tab:cva}). One option is to harmonize protocols, assuming harmonized protocols have $CV_a$ values below those estimated from our sites. The other option is to recruit more subjects per site. Our power equation can define just how many more subjects are needed to overcome a large $CV_a$. In the case of the parameters defined in figure \ref{fig:cv_j} (a small effect size of 0.2, false positive rate of 0.002), the difference is simply an extra 40 subjects overall, since the point on the curve for 2300 total subjects over 20 sites lies above the harmonization zone. The number of extra subjects needed changes with chosen effect sizes, false positive rates, power requirements, and site-level sample size. 

We have validated our scaling factors by demonstrating that a leave-one-out calibration resulted in increased absolute agreement between sites compared to the original, uncalibrated values, for 44 out of 46 ROIs studied. Tables \ref{comparetocannon} and \ref{comparetojov} compare these calibrated and original values to the ICC findings of other harmonization efforts. Table \ref{comparetocannon} compares our between-site ICCs before and after scaling factor calibration to those of \cite{cannon2014}. \cite{cannon2014} used different segmentation algorithms for subcortical and cortical ROIs. For the cortical ROIs, they used a cortical pattern matching algorithm \cite{thompson2001detecting} and for the subcortical ROIs, they utilized FSL's FIRST algorithm. The between-site ICC for gray matter volume (GMV) for our study was .78 while \cite{cannon2014} reported an ICC of .85. This difference could be explained by the harmonization of scanners in \cite{cannon2014}. After using the scaling factors to calibrated GMV, the between-site ICC increased to .96, implying that the estimated $CV_a$ of GMV (4\%) is an accurate representation of the true between site bias variability. Scaling calibration of the hippocampus also outperformed the between site ICC of \cite{cannon2014}, at 0.84 versus 0.79, validating the $CV_a$ estimate of 3\% for both hemispheres. For the amygdala and caudate volumes, scaling calibration showed improvement to nearly the same value as \cite{cannon2014}, where the amygdala went from 0.54 to 0.74 versus 0.76, and the ICC of the caudate went from 0.82 to 0.91 versus 0.92. The $CV_a$ of the left and right amygala were the highest, at 7 and 9 percent respectively. There was asymmetry in the scaling factors of the left and right caudate, at 2\% and 7\%. The between site ICC of white matter volume (WMV) was very high compared to that of \cite{cannon2014} (0.96 versus 0.774) and it was very low for the thalamus (.61 versus .95), even after scaling factor calibration. This could be due to differences in algorithms used, and because the scan-rescan reliability of the thalamus was particularly low in some sites, which propagated errors to scaling factor estimates. Therefore, the 5\% $CV_a$ estimate for the thalamus in both hemispheres may not be accurate, and would need to be recalculated using a different algorithm with more stable scan-rescan reliability. 

Table \ref{comparetojov} shows comparisons of our within-site ICC to the average within-site ICCs reported by \cite{jovicich2013brain}, where scanners were not strictly standardized and the same freesurfer cross-sectional algorithm was run. All within site ICC's, before and after scaling factor calibration, fall within the range described by \cite{jovicich2013brain}, including the thalamus.  Our last attempt to validate our scaling factor estimates and model was to simulate multisite data using scaling factor estimates and their residual error from the estimate. We found that the power curves align closely, and match when power is at least 80\%. We believe that the small deviations from the theoretical model is a result of the scaling factor estimation error and a relatively small sampling of scaling factors which led to a distribution of 20 scaling factors was not normal.  

The data acquisition of our study is similar to that of \cite{Schnack_2004}, where the researchers acquired T1-weighted images from 8 multicenter human phantoms across 5 sites with non-standardized protocols. These scanners were all 1.5T except for one 1T scanner. \cite{Schnack_2004} calibrated the intensity histograms of the images before segmentation with a calibration factor that was estimated based on the absolute agreement of volumes to the reference site (ICC). After calibration, the ICC's of the lateral ventricle was $\geq 0.96$ compared to our pre- and post- calibrated result of $0.97$. The ICC for the intensity calibrated gray matter volume in \cite{Schnack_2004} was $\geq 0.84$, compared to our calibrated between-site ICC of $0.78$ (uncalibrated), and $0.96$ (calibrated). The ICC for the intensity calibrated  white matter volume in \cite{Schnack_2004} was $\geq .78$ whereas our between-site ICCs were $0.96$ and $0.98$ for the pre- and post- calibrated volumes respectively. Because MS is a white matter disease, all the sites in our consortium study chose scan parameters to maximize the contrast of white matter and the reliability of the volume estimates, which could be why our WMV between-site ICC is much higher than that of \cite{Schnack_2004} and \cite{cannon2014}. Most importantly, the calibration method of \cite{Schnack_2004} requires the acquisition of multisite phantoms, while the results of our direct-volume calibration (the estimates of $CV_a$ for each ROI) allows studies to collect sample sizes based on our  porposed power equation. 