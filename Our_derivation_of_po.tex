The above derivation of power for a multisite study defines hard thresholds for the amount of acceptable scaling factor variability ($CV_{a}$) using scaled, systematic error from MRI. Many factors contribute to the $CV_{a}$ cut-off, such as the total number of subjects, total number of sites, effect size, and false positive rate. In Figure \ref{fig:cv_j}, we show the distribution of experimental $CV_{a}$ values across all Freesurfer aseg ROIs to reference while comparing power curves of various sample sizes. The maximum $CV_{a}$ value is 9\% which, with enough subjects and sites, falls well below the maximum acceptable $CV_{a}$ value. However, with the minimum number of subjects and sites, the power curves of figure \ref{fig:cv_j} show that the maximum acceptable $CV_{\alpha}$ must be below 5\% for 80\% power. If we minimize the total number of subjects to 2260 for the 20 sites in our study, the $CV_{a}$ of the amygdala does not meet this requirement (see table \ref{tab:cva}). One option to address this is to harmonize protocols, which may reduce $CV_a$ values below those estimated from our sites such that they satisfy the maximum $CV_{a}$ requirement. The other option is to recruit more subjects per site. The number of additional subjects needed to overcome a large $CV_a$ can be estimated using our power equation. In the case of the parameters defined in figure \ref{fig:cv_j} (a small effect size of 0.2, false positive rate of 0.002), 40 additional subjects beyond the initial 2260 are needed to adequately power the study. This is easily visualized in figure \ref{fig:cv_j}: the point on the curve for the initial 2260 subjects over 20 sites lies below the harmonization zone, while that of 2300 total subjects lies above. The number of additional subjects needed to achieve an adequately powered multisite study depends on effect sizes, false positive rates, power requirements, and site-level sample size. 

We have validated our scaling factors by demonstrating that a leave-one-out calibration resulted in increased absolute agreement between sites compared to the original, uncalibrated values for 44 out of 46 ROIs studied. Tables \ref{comparetocannon} and \ref{comparetojov} compare these calibrated and original values to the ICC findings of other harmonization efforts. Table \ref{comparetocannon} compares our between-site ICCs before and after scaling factor calibration to those of \cite{cannon2014}. \cite{cannon2014} used a cortical pattern matching segmentation algorithm \cite{thompson2001detecting} for the cortical ROIs and FSL's FIRST algorithm for the subcortical ROIs. The between-site ICC for gray matter volume (GMV) for our study was 0.78 while \cite{cannon2014} reported an ICC of 0.85. This difference could be explained by the harmonization of scanners in \cite{cannon2014}. After using the scaling factors to calibrate GMV, the between-site ICC increased to 0.96, indicating that the estimated $CV_a$ of GMV (4\%) is an accurate representation of the true between-site bias variability. Scaling calibration of the hippocampus also outperformed the between-site ICC of \cite{cannon2014} (0.84 versus 0.79), validating the $CV_a$ estimate of 3\% for both hemispheres. For the amygdala and caudate volumes, scaling calibration showed improvement to nearly the same value as \cite{cannon2014}. The amygdala increased from 0.54 to 0.74 (versus 0.76 in the \cite{cannon2014}), and the ICC of the caudate increased from 0.82 to 0.91 (versus 0.92 in the \cite{cannon2014}). The $CV_a$ of the left and right amygala were the highest in our study, at 7 and 9 percent, respectively. The most extreme asymmetry in the scaling factors was between the left and right caudate (2\% and 7\%, respectively), which demonstrates regional contrast to noise variation. Even after scaling factor calibration, the between-site ICC produced by our approach varied widely from that of \cite{cannon2014} in two ROIs. The between-site ICC of white matter volume (WMV) was very high (0.96 versus 0.774) and that of thalamus volume was very low (.61 versus .95), compared to \cite{cannon2014}. This could be due to differences algorithm differences (FIRST vs. Freesurfer). It should also be noted that the scan-rescan reliability of the thalamus was particularly low in some sites, which propagated errors to scaling factor estimates. Therefore, the 5\% $CV_a$ estimate for the thalamus in both hemispheres may not be reproducible and would need to be recalculated using a different algorithm. 

Table \ref{comparetojov} shows comparisons of our within-site ICCs to the average within-site ICCs reported by \cite{jovicich2013brain}. Similar to our study, scanners were not strictly standardized and the freesurfer cross-sectional algorithm was run. All within site ICCs (both before and after scaling factor calibration) fall within the range described by \cite{jovicich2013brain}, including the thalamus. 
Our last attempt to validate this statistical model and accompanying scaling factor estimates was to simulate multisite data using scaling factor estimates and their residual error from the estimate. We found that the power curves align closely, and match when power is at least 80\%. We believe that the small deviations from the theoretical model result from scaling factor estimation error and a non-normal scaling factor distribution due to a relatively small sampling of scaling factors (J = 20 sites).  

The data acquisition of our study is similar to that of \cite{Schnack_2004}, in which the researchers acquired T1-weighted images from 8 consistent human phantoms across 5 sites with non-standardized protocols. These scanners were all 1.5T except for one 1T scanner. \cite{Schnack_2004} calibrated the intensity histograms of the images before segmentation with a calibration factor estimated based on the absolute agreement of volumes to the reference site (ICC). After applying their calibration method, the ICC of the lateral ventricle was $\geq 0.96$, which is similar to our pre- and post- calibrated result of $0.97$. The ICC for the intensity calibrated gray matter volume in \cite{Schnack_2004} was $\geq 0.84$, compared to our calibrated between-site ICC of $0.78$ (uncalibrated), and $0.96$ (calibrated). Our between-site ICCs for white matter volume ($0.96$ and $0.98$ for the pre- and post- calibrated volumes, respectively) were much higher than those of the intensity calibrated  white matter volume in \cite{Schnack_2004} ($\geq .78$). This could be explained by the fact that our cohort of sites is a consortium studying multiple sclerosis, which is a white matter disease, so there may be a bias toward optimizing scan parameters for white matter. Most importantly, the calibration method of \cite{Schnack_2004} requires re-acquisition of a human phantom cohort at each site for each multisite study. Alternatively, multisite studies employing our approach can use the results of our direct-volume calibration (the estimates of $CV_a$ for each ROI) to estimate sample sizes based on our proposed power equation and bias measurements without acquiring their own human phantom dataset to use in calibration.